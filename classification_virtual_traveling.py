# -*- coding: utf-8 -*-
"""ML Project 1: Virtual Traveling

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rfP2Tu66nw-Zt-nDHDrtcj9y1xmYlloq
"""

import numpy as np
import pandas as pd
from collections import Counter
import matplotlib.pyplot as plt

DATASET = np.load('data_virtualTraveling.npz')

class Dataset:
  def __init__(self):
    self.X = DATASET['X']
    self.Y = DATASET['Y']

  def description(self):
    for k in DATASET.files:
      print(k)
    print(self.X.shape)
    print(len(self.X))
    print(self.Y.shape)
    print(self.Y)
    print(self.X[0].shape)

  def plot(self):
    for img in self.X[:10]:
      plt.figure()
      print(f'Shape: {img.shape}')
      print("Values min/max", img.min(), img.max())
      plt.imshow(img)
      plt.grid()
      plt.show()


dataset = Dataset()
dataset.description()
dataset.plot()

"""There are 1186 images in dataset. and each image dataset is of shape: (299, 299, 3)

- K Nearest Neighbour
- decission tree
- random forest
- clustering
"""

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties
from skimage import color
from sklearn import metrics
from itertools import cycle
from skimage.transform import rescale, resize, downscale_local_mean
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_predict
from sklearn.multioutput import MultiOutputClassifier
from google.colab import files

DATASET = np.load('/content/drive/MyDrive/Bielefeld University/machine learning/data_virtualTraveling.npz')

CV = KFold(n_splits=3)

def dataset():
  X = DATASET['X']
  Y = DATASET['Y']
  X_downscaled = np.array([downscale_local_mean(img, (3, 3, 1)) for img in X])
  # X_gray = np.array([color.rgb2gray(img) for img in X_downscaled])
  # print(X_downscaled.shape, X_gray.shape)
  X_transformed = X_downscaled.reshape(X_downscaled.shape[0], -1)
  n_classes = Y.shape[1]
  # for img in X_gray[:5]:
  #     plt.figure()
  #     print(f'Shape: {img.shape}')
  #     plt.imshow(img)
  #     plt.grid()
  #     plt.show()
  return X, X_transformed, Y, n_classes

def model_training(model, X, Y):
  y_pred = cross_val_predict(model, X, Y, cv=CV)
  return y_pred

def roc_scores(Y, y_pred, n_classes):
  fpr = dict()
  tpr = dict()
  roc_auc = dict()
  for i in range(n_classes):
      fpr[i], tpr[i], _ = metrics.roc_curve(Y[:, i], y_pred[:, i])
      roc_auc[i] = metrics.auc(fpr[i], tpr[i])
  return fpr, tpr, roc_auc

def plot_roc(fpr, tpr, roc_auc, n_classes, model_name):
  fpr["micro"], tpr["micro"], _ = metrics.roc_curve(Y.ravel(), y_pred.ravel())
  roc_auc["micro"] = metrics.auc(fpr["micro"], tpr["micro"])
  all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))
  mean_tpr = np.zeros_like(all_fpr)
  for i in range(n_classes):
      mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])
  mean_tpr /= n_classes
  fpr["macro"] = all_fpr
  tpr["macro"] = mean_tpr
  roc_auc["macro"] = metrics.auc(fpr["macro"], tpr["macro"])
  plt.figure()
  plt.plot(fpr["micro"], tpr["micro"],
          label='micro-average ROC curve (area = {0:0.2f})'
                ''.format(roc_auc["micro"]),
          color='deeppink', linestyle=':', linewidth=4)

  plt.plot(fpr["macro"], tpr["macro"],
          label='macro-average ROC curve (area = {0:0.2f})'
                ''.format(roc_auc["macro"]),
          color='navy', linestyle=':', linewidth=4)

  colors = cycle(["red", "yellow", 'green', 'darkorange', 'cornflowerblue'])
  lw = 2
  for i, color in zip(range(n_classes), colors):
      plt.plot(fpr[i], tpr[i], color=color, lw=lw,
              label='ROC curve of class {0} (area = {1:0.2f})'
              ''.format(i, roc_auc[i]))

  plt.plot([0, 1], [0, 1], 'k--', lw=lw)
  plt.xlim([0.0, 1.0])
  plt.ylim([0.0, 1.05])
  plt.xlabel('False Positive Rate')
  plt.ylabel('True Positive Rate')
  plt.title('Receiver operating characteristic')
  fontP = FontProperties()
  fontP.set_size('xx-small')
  plt.legend(loc="lower right", prop=fontP)
  filename = "ROC_"+model_name+".eps"
  plt.savefig(filename, format="eps")
  files.download(filename)
  # plt.show()

def confusion_matrix(Y, y_pred, model_name):
  matrices = metrics.multilabel_confusion_matrix(Y, y_pred, labels=[0,1,2,3,4])
  print(matrices)
  labels=["Snow/Ice", "Mountains/Rocks", "Plants/Forrests", "Stars", "Sandy Desert"]
  fig, axs = plt.subplots(2, 3, figsize=(10, 8), constrained_layout=True)
  for i in range(len(labels)):
    ax = axs[0, i] if i<=2 else axs[1, i-3]
    disp = metrics.ConfusionMatrixDisplay(confusion_matrix=matrices[i], display_labels=[False, True])
    disp.plot(ax=ax, values_format = 'd')
    disp.ax_.set_title(labels[i])
  fig.delaxes(axs[1, 2])
  filename = model_name+"_Confusion_matrix_for_"+labels[i].replace("/","or")+".eps"
  plt.savefig(filename, format="eps")
  files.download(filename)
  # plt.show()

X, X_transformed, Y, n_classes = dataset()

from sklearn.tree import DecisionTreeClassifier

y_pred = model_training(MultiOutputClassifier(DecisionTreeClassifier(max_depth=15)), X_transformed, Y)
print(metrics.roc_auc_score(Y, y_pred), metrics.accuracy_score(Y, y_pred))
fpr, tpr, roc_auc = roc_scores(Y, y_pred, n_classes)
print(fpr, tpr, roc_auc)
plot_roc(fpr, tpr, roc_auc, n_classes, "DecisionTreeClassifier")
confusion_matrix(Y, y_pred, "DecisionTreeClassifier")

from sklearn.neighbors import KNeighborsClassifier

y_pred = model_training(MultiOutputClassifier(KNeighborsClassifier(n_neighbors=10)), X_transformed, Y)
print(metrics.roc_auc_score(Y, y_pred), metrics.accuracy_score(Y, y_pred))
fpr, tpr, roc_auc = roc_scores(Y, y_pred, n_classes)
print(fpr, tpr, roc_auc)
plot_roc(fpr, tpr, roc_auc, n_classes,"KNeighborsClassifier")
confusion_matrix(Y, y_pred, "KNeighborsClassifier")

from sklearn.ensemble import RandomForestClassifier

y_pred = model_training(MultiOutputClassifier(RandomForestClassifier()), X_transformed, Y)
print(metrics.roc_auc_score(Y, y_pred), metrics.accuracy_score(Y, y_pred))
fpr, tpr, roc_auc = roc_scores(Y, y_pred, n_classes)
print(fpr, tpr, roc_auc)
plot_roc(fpr, tpr, roc_auc, n_classes, "RandomForestClassifier")
confusion_matrix(Y, y_pred, "RandomForestClassifier")

from sklearn.linear_model import RidgeClassifier
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_std = scaler.fit_transform(X_transformed)
y_pred = model_training(MultiOutputClassifier(RidgeClassifier(alpha=10.0)), X_std, Y)
print(metrics.roc_auc_score(Y, y_pred), metrics.accuracy_score(Y, y_pred))
fpr, tpr, roc_auc = roc_scores(Y, y_pred, n_classes)
print(fpr, tpr, roc_auc)
plot_roc(fpr, tpr, roc_auc, n_classes, "RidgeClassifier")
confusion_matrix(Y, y_pred, "RidgeClassifier")

